2. Quick interpretation of trends

Let me summarize the average final HPWL vs. settings:

Î± = 0.85 (fast cooling)
N	Runtime	HPWL (avg)
100	~108 s	~427k
200	~210 s	~387k
400	~428 s	~330k

Fast cooling â†’ worse solutions, but fast runtime.

Î± = 0.92 (medium cooling)

This is where things get weird, because you have a few very slow outliers:

One took 10,032 seconds (2.8 hours!)

Another 20,830 seconds (5.7 hours!)

That tells me your max_iterations is being hit, especially for Î±=0.92 & Nâ‰¥200.

But the results still follow the trend:

N	Runtime	HPWL (avg)
100	huge variance	~394k
200	huge variance	~335k
400	variable	~271k

Even with unpredictable runtime, HPWL improves meaningfully.

This also means:

ðŸ‘‰ Î± = 0.92 is too slow unless you limit max_iterations
(which is fine to mention in your analysis)

Î± = 0.97 (slow cooling)

These are the best placements:

N	Runtime	HPWL (avg)
100	~566 s	~306k
200	~1,126 s	~246k
400	~2,800 s	~215k

This shows:

Very slow but extremely high-quality results

Classic asymptotic SA improvement

ðŸ§  3. The Pareto frontier (from the CSV)

We are minimizing:

Runtime (lower)

HPWL (lower)

From visual inspection, the Pareto points should include:

Î±	N	Runtime	HPWL
0.85	100	107 s	~427k
0.85	200	209 s	~382k
0.85	400	428 s	~330k
0.97	100	566 s	~305k
0.97	200	1,116 s	~246k
0.97	400	2,800 s	~215k

Any Î±=0.92 results are dominated by Î±=0.97:

Same runtime class â†’ worse HPWL

Same HPWL class â†’ much slower

So:

ðŸ‘‰ The 0.92 runs will fall OFF the Pareto frontier
ðŸ‘‰ This is a great talking point in the README


Note:
10,032 s
20,830 s
2,999 s

are outliers, likely due to laptop sleep while running